{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,Flatten,Dense,MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(horizontal_flip=True,rescale=1./255,zoom_range=0.2) \n",
    "#rescale=1./255 means transform every pixel value from range [0,255] -> [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2508 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "X_train=train_datagen.flow_from_directory(r'C:\\Users\\Dell\\Downloads\\garbage collection\\dataset\\Training',\n",
    "                                          \n",
    "                                          target_size=(128,128),class_mode='categorical',batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 464 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "X_test=test_datagen.flow_from_directory(r'C:\\Users\\Dell\\Downloads\\garbage collection\\dataset\\Testing',\n",
    "                                        target_size=(128,128),class_mode='categorical',batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cardboard': 0, 'glass': 1, 'metal': 2, 'paper': 3, 'plastic': 4, 'trash': 5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelBuilding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)convolution layer\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu',padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)convolution layer\n",
    "model.add(Convolution2D(32,(3,3),activation='relu',padding='same'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten layer \n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,144\n",
      "Trainable params: 10,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(300,activation='relu'))#hidden layer\n",
    "model.add(Dense(150,activation='relu'))#hidden layer\n",
    "model.add(Dense(6,activation='softmax'))#output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp/ipykernel_24804/1309883764.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(X_train,validation_data=X_test,epochs=40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "26/26 [==============================] - 82s 3s/step - loss: 2.1797 - accuracy: 0.1994 - val_loss: 1.7443 - val_accuracy: 0.2241\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 79s 3s/step - loss: 1.6578 - accuracy: 0.3114 - val_loss: 1.5193 - val_accuracy: 0.4440\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 80s 3s/step - loss: 1.4889 - accuracy: 0.4127 - val_loss: 1.4543 - val_accuracy: 0.3944\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 81s 3s/step - loss: 1.4266 - accuracy: 0.4338 - val_loss: 1.3869 - val_accuracy: 0.4806\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 80s 3s/step - loss: 1.2993 - accuracy: 0.4984 - val_loss: 1.3030 - val_accuracy: 0.5194\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 82s 3s/step - loss: 1.2529 - accuracy: 0.5132 - val_loss: 1.4116 - val_accuracy: 0.4504\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 91s 3s/step - loss: 1.1547 - accuracy: 0.5518 - val_loss: 1.2933 - val_accuracy: 0.5366\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 87s 3s/step - loss: 1.1501 - accuracy: 0.5654 - val_loss: 1.2475 - val_accuracy: 0.5280\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 90s 3s/step - loss: 1.0432 - accuracy: 0.6144 - val_loss: 1.1853 - val_accuracy: 0.5948\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 84s 3s/step - loss: 0.9789 - accuracy: 0.6519 - val_loss: 1.0844 - val_accuracy: 0.6056\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 80s 3s/step - loss: 0.9567 - accuracy: 0.6543 - val_loss: 1.1548 - val_accuracy: 0.5539\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 80s 3s/step - loss: 0.9102 - accuracy: 0.6603 - val_loss: 1.0472 - val_accuracy: 0.6444\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 81s 3s/step - loss: 0.8284 - accuracy: 0.6922 - val_loss: 1.0187 - val_accuracy: 0.6767\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 81s 3s/step - loss: 0.7313 - accuracy: 0.7392 - val_loss: 1.0476 - val_accuracy: 0.6659\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 83s 3s/step - loss: 0.8091 - accuracy: 0.7089 - val_loss: 1.0344 - val_accuracy: 0.6638\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.7258 - accuracy: 0.7341 - val_loss: 0.9984 - val_accuracy: 0.6853\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.6677 - accuracy: 0.7636 - val_loss: 1.0407 - val_accuracy: 0.6530\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.6153 - accuracy: 0.7819 - val_loss: 1.0557 - val_accuracy: 0.6918\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.6845 - accuracy: 0.7592 - val_loss: 0.9559 - val_accuracy: 0.7198\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 81s 3s/step - loss: 0.5983 - accuracy: 0.7847 - val_loss: 0.9378 - val_accuracy: 0.7134\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.4746 - accuracy: 0.8353 - val_loss: 1.0419 - val_accuracy: 0.6918\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 81s 3s/step - loss: 0.4757 - accuracy: 0.8274 - val_loss: 0.9492 - val_accuracy: 0.7349\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.4513 - accuracy: 0.8449 - val_loss: 1.0788 - val_accuracy: 0.6746\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 81s 3s/step - loss: 0.4002 - accuracy: 0.8604 - val_loss: 1.1182 - val_accuracy: 0.6875\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.4064 - accuracy: 0.8573 - val_loss: 1.0956 - val_accuracy: 0.7026\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 83s 3s/step - loss: 0.4014 - accuracy: 0.8600 - val_loss: 0.9277 - val_accuracy: 0.7241\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.3637 - accuracy: 0.8700 - val_loss: 1.0288 - val_accuracy: 0.6961\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 76s 3s/step - loss: 0.3375 - accuracy: 0.8840 - val_loss: 1.3130 - val_accuracy: 0.6573\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 83s 3s/step - loss: 0.3178 - accuracy: 0.8856 - val_loss: 1.1468 - val_accuracy: 0.6746\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 80s 3s/step - loss: 0.3256 - accuracy: 0.8896 - val_loss: 0.9976 - val_accuracy: 0.7457\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 80s 3s/step - loss: 0.3037 - accuracy: 0.8963 - val_loss: 1.1288 - val_accuracy: 0.7155\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 81s 3s/step - loss: 0.3245 - accuracy: 0.8820 - val_loss: 1.0302 - val_accuracy: 0.7091\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 81s 3s/step - loss: 0.2609 - accuracy: 0.9147 - val_loss: 1.0797 - val_accuracy: 0.7047\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 81s 3s/step - loss: 0.2431 - accuracy: 0.9167 - val_loss: 0.9990 - val_accuracy: 0.7392\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 79s 3s/step - loss: 0.2053 - accuracy: 0.9314 - val_loss: 1.0972 - val_accuracy: 0.7306\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 78s 3s/step - loss: 0.2413 - accuracy: 0.9159 - val_loss: 1.2258 - val_accuracy: 0.7091\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.2164 - accuracy: 0.9302 - val_loss: 1.1342 - val_accuracy: 0.7155\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 81s 3s/step - loss: 0.2174 - accuracy: 0.9262 - val_loss: 1.1446 - val_accuracy: 0.7435\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.2362 - accuracy: 0.9199 - val_loss: 1.2590 - val_accuracy: 0.7047\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 81s 3s/step - loss: 0.1949 - accuracy: 0.9386 - val_loss: 1.1133 - val_accuracy: 0.7435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e769998fa0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training \n",
    "#Note :increse epochs number\n",
    "model.fit_generator(X_train,validation_data=X_test,epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('garbage1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model=load_model(r\"C:\\Users\\Dell\\Downloads\\garbage collection\\training\\garbage.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#patch of image you  want to predict \n",
    "img=image.load_img(r'C:\\Users\\Dell\\Downloads\\garbage collection\\dataset\\Testing\\glass\\glass422.jpg',target_size=(128,128))\n",
    "x=image.img_to_array(img)#img to array\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.expand_dims(x,axis=0)#used for adding one more dimension\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 534ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=model.predict(x)#instead of predict_classes(x) we can use predict(X)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "prediction = np.argmax(prediction)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[\"cardbord\",\"glass\",\"metal\",\"paper\",\"plastic\",\"trash\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trash'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=str(index[prediction])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "#model=load_model(\"garbage.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8adb3b6b06e3681f9285198c54846cbe87e14e4c23e5f143135856c18f49bf3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
